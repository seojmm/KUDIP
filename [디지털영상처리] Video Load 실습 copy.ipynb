{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad8b815",
   "metadata": {},
   "source": [
    "## Video Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install matplotlib==3.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d94b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7b6bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path, ms=100):\n",
    "    \n",
    "    # Video Capture 객체 생성\n",
    "    capture = cv2.VideoCapture(path)\n",
    "    \n",
    "    # Frame을 저장할 List 선언\n",
    "    frames = []\n",
    "    \n",
    "    while capture.isOpened(): # Video Capture가 준비되었는지 확인\n",
    "        \n",
    "        run, frame = capture.read() # 다음 Frame 읽기\n",
    "        \n",
    "        if run: # Frame을 읽은 경우\n",
    "            cv2.imshow(\"video\", frame)\n",
    "            cv2.waitKey(ms) # Millisecond 단위로 대기\n",
    "        else: # 재생이 완료되어 더 이상 Frame을 읽을 수 없는 경우\n",
    "            break\n",
    "        \n",
    "        # Frame List에 추가\n",
    "        frames.append(frame)\n",
    "\n",
    "    capture.release() # Capture 자원 반납\n",
    "    cv2.destroyAllWindows() # 창 제거\n",
    "    \n",
    "    return np.array(frames, dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad920ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video가 저장된 경로 입력\n",
    "PATH ='/Users/yunjinkim/Desktop/디지털영상처리/video.mov'\n",
    "# PATH = r\"C:\\Users\\admin\\Desktop\\KUDIP\\Video Samples\\Hand Video2.mov\"\n",
    "# PATH = r\"C:\\Users\\hj\\AICV\\수업\\디지털영상처리\\Video Samples\\highway.mov\"\n",
    "# PATH = r\"C:\\Users\\hj\\AICV\\수업\\디지털영상처리\\Video Samples\\earth.avi\"\n",
    "\n",
    "# Video 재생 및 반환 (Numpy Array)\n",
    "video = load_video(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42987dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Data Type: <class 'numpy.ndarray'>\n",
      "- Data Shape: (4181, 442, 978, 3) *Frames x Height x Width x Channel\n",
      "- Maximum Intensity: 255\n",
      "- Minimum Intensity: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"- Data Type: {type(video)}\")\n",
    "print(f\"- Data Shape: {video.shape} *Frames x Height x Width x Channel\")\n",
    "print(f\"- Maximum Intensity: {video.max()}\")\n",
    "print(f\"- Minimum Intensity: {video.min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b51e35c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Push-ups Counted: 95\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_video(path, ms=100):\n",
    "    capture = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    \n",
    "    while capture.isOpened():\n",
    "        run, frame = capture.read()\n",
    "        if run:\n",
    "            frames.append(frame)\n",
    "        else:\n",
    "            break\n",
    "        cv2.imshow(\"video\", frame)\n",
    "        cv2.waitKey(ms)\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()dnld\n",
    "    return np.array(frames, dtype='uint8')\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # 피부색 범위 설정 (손의 피부색 감지)\n",
    "    lower_skin = np.array([0, 20, 70], dtype=np.uint8)\n",
    "    upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
    "    \n",
    "    # 피부색 영역 검출\n",
    "    mask = cv2.inRange(hsv, lower_skin, upper_skin)\n",
    "    \n",
    "    # 블러링 적용 (노이즈 제거)\n",
    "    blurred = cv2.GaussianBlur(mask, (5, 5), 0)\n",
    "    \n",
    "    return blurred\n",
    "\n",
    "def detect_hand_area(mask):\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "def get_position_and_bounding_box(contours):\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        position = (x + w // 2, y + h // 2)  # 중앙 위치\n",
    "        return position, (x, y, w, h)\n",
    "    return None, None\n",
    "\n",
    "def draw_box(frame, box, color=(255, 0, 0)):\n",
    "    if box:\n",
    "        x, y, w, h = box\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "\n",
    "def count_pushups(frames):\n",
    "    pushup_count = 0\n",
    "    initial_hand_position = None\n",
    "    is_touching = False\n",
    "\n",
    "    for frame in frames:\n",
    "        mask = preprocess_frame(frame)\n",
    "        \n",
    "        hand_contours = detect_hand_area(mask)\n",
    "\n",
    "        hand_position, hand_box = get_position_and_bounding_box(hand_contours)\n",
    "\n",
    "        draw_box(frame, hand_box, (255, 0, 0))\n",
    "\n",
    "        if hand_position:\n",
    "            current_hand_y = hand_position[1]  # 손의 y 위치\n",
    "\n",
    "            if initial_hand_position is None:\n",
    "                initial_hand_position = current_hand_y\n",
    "\n",
    "            # 손의 색상이 변하면 (무언가 닿으면) 푸쉬업 카운트\n",
    "            if current_hand_y < initial_hand_position - 5 and not is_touching:\n",
    "                is_touching = True\n",
    "            elif current_hand_y > initial_hand_position + 5 and is_touching:\n",
    "                is_touching = False\n",
    "                pushup_count += 1\n",
    "\n",
    "            initial_hand_position = current_hand_y\n",
    "\n",
    "        cv2.imshow(\"Processed Video\", frame)\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    return pushup_count\n",
    "\n",
    "# 비디오 경로 설정\n",
    "video_path = '/Users/yunjinkim/Desktop/디지털영상처리/video.mov'\n",
    "\n",
    "# 비디오 로드\n",
    "video_frames = load_video(video_path)\n",
    "\n",
    "# 푸쉬업 카운팅\n",
    "pushup_count = count_pushups(video_frames)\n",
    "print(f\"Total Push-ups Counted: {pushup_count}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aadf52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def calculate_circularity(contour):\n",
    "    area = cv2.contourArea(contour)\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    circularity = (4 * np.pi * area) / (perimeter ** 2)\n",
    "    return circularity\n",
    "\n",
    "def find_largest_circularity_contour(contours):\n",
    "    max_circularity = -1\n",
    "    largest_contour = None\n",
    "    \n",
    "    for contour in contours:\n",
    "        circularity = calculate_circularity(contour)\n",
    "        if circularity > max_circularity:\n",
    "            max_circularity = circularity\n",
    "            largest_contour = contour\n",
    "    \n",
    "    return largest_contour\n",
    "\n",
    "def find_center_of_contour(contour):\n",
    "    ((x, y), _radius) = cv2.minEnclosingCircle(contour)\n",
    "    center = (int(x), int(y))\n",
    "    return center\n",
    "\n",
    "def high_boost_filter(image, kernel_size=3, k=1.2):\n",
    "    blur = cv2.blur(image, (kernel_size, kernel_size))\n",
    "    high_boost_image = image * k - blur\n",
    "    return high_boost_image\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    intensity = hsv[:, :, 2]\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    opening = cv2.morphologyEx(intensity, cv2.MORPH_DILATE, kernel)\n",
    "    hsv[:, :, 2] = opening\n",
    "    result = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    return result\n",
    "\n",
    "def detect_skin(img):\n",
    "    img_HSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    HSV_mask = cv2.inRange(img_HSV, (0, 15, 0), (17, 170, 255)) \n",
    "    HSV_mask = cv2.morphologyEx(HSV_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "    img_YCrCb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    YCrCb_mask = cv2.inRange(img_YCrCb, (0, 135, 85), (255, 180, 135)) \n",
    "    YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "    global_mask = cv2.bitwise_and(YCrCb_mask, HSV_mask)\n",
    "    global_mask = cv2.medianBlur(global_mask, 5)\n",
    "    global_mask = cv2.morphologyEx(global_mask, cv2.MORPH_OPEN, np.ones((7,7), np.uint8))\n",
    "    return global_mask\n",
    "\n",
    "def detect_hand_area(mask):\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "def get_position_and_bounding_box(contours):\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        position = (x + w // 2, y + h // 2)\n",
    "        return position, (x, y, w, h)\n",
    "    return None, None\n",
    "\n",
    "def draw_box(frame, box, color=(255, 0, 0)):\n",
    "    if box:\n",
    "        x, y, w, h = box\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "\n",
    "def count_pushups(head_positions):\n",
    "    count = 0\n",
    "    state = 0  # 0: 시작, 1: 내려감, 2: 올라옴\n",
    "    for i in range(1, len(head_positions)):\n",
    "        if head_positions[i-1] is None or head_positions[i] is None:\n",
    "            continue\n",
    "        if state == 0 and head_positions[i][1] > head_positions[i-1][1]:\n",
    "            state = 1\n",
    "        elif state == 1 and head_positions[i][1] < head_positions[i-1][1]:\n",
    "            count += 1\n",
    "            state = 2\n",
    "        elif state == 2 and head_positions[i][1] > head_positions[i-1][1]:\n",
    "            state = 1\n",
    "    return count\n",
    "\n",
    "def main(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    head_positions = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        preprocessed_frame = preprocess_frame(frame)\n",
    "        skin_mask = detect_skin(preprocessed_frame)\n",
    "        hand_contours = detect_hand_area(skin_mask)\n",
    "        hand_position, hand_box = get_position_and_bounding_box(hand_contours)\n",
    "        \n",
    "        if hand_position:\n",
    "            head_positions.append(hand_position)\n",
    "            draw_box(frame, hand_box)\n",
    "\n",
    "        cv2.imshow(\"Processed Video\", frame)\n",
    "        \n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    pushup_count = count_pushups(head_positions)\n",
    "    print(f\"Total Push-ups Counted: {pushup_count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"pushup_sample2.mp4\"\n",
    "    main(video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609fb5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#64회"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
