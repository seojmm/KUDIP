{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path, ms=100):\n",
    "    \n",
    "    # Video Capture 객체 생성\n",
    "    capture = cv2.VideoCapture(path)\n",
    "    \n",
    "    # Frame을 저장할 List 선언\n",
    "    frames = []\n",
    "    \n",
    "    while capture.isOpened(): # Video Capture가 준비되었는지 확인\n",
    "        \n",
    "        run, frame = capture.read() # 다음 Frame 읽기\n",
    "        # ROI 설정 (x, y, width, height)\n",
    "        roi_x, roi_y, roi_w, roi_h = 0, 280, 852, 200\n",
    "        \n",
    "        # ROI 추출\n",
    "        roi = frame[roi_y:roi_y + roi_h, roi_x:roi_x + roi_w]\n",
    "\n",
    "        # 그레이스케일 변환\n",
    "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        edges = cv2.Canny(blurred, 50, 150)\n",
    "        # 원본 프레임에 엣지 결과를 덮어쓰기 (ROI 영역만)\n",
    "        frame[roi_y:roi_y + roi_h, roi_x:roi_x + roi_w] = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        \n",
    "        if run: # Frame을 읽은 경우\n",
    "            # 결과 출력\n",
    "            cv2.imshow('Frame with ROI Edges', frame)\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else: # 재생이 완료되어 더 이상 Frame을 읽을 수 없는 경우\n",
    "            break\n",
    "        \n",
    "        # Frame List에 추가\n",
    "        frames.append(frame)\n",
    "\n",
    "    capture.release() # Capture 자원 반납\n",
    "    cv2.destroyAllWindows() # 창 제거\n",
    "    \n",
    "    return np.array(frames, dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video가 저장된 경로 입력\n",
    "PATH = r\".\\plank_sample2.mp4\"\n",
    "# PATH = r\"C:\\Users\\admin\\Desktop\\KUDIP\\Video Samples\\Hand Video2.mov\"\n",
    "# PATH = r\"C:\\Users\\hj\\AICV\\수업\\디지털영상처리\\Video Samples\\highway.mov\"\n",
    "# PATH = r\"C:\\Users\\hj\\AICV\\수업\\디지털영상처리\\Video Samples\\earth.avi\"\n",
    "\n",
    "# Video 재생 및 반환 (Numpy Array)\n",
    "video = load_video(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Data Type: <class 'numpy.ndarray'>\n",
      "- Data Shape: (79, 480, 852, 3) *Frames x Height x Width x Channel\n",
      "- Maximum Intensity: 255\n",
      "- Minimum Intensity: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"- Data Type: {type(video)}\")\n",
    "print(f\"- Data Shape: {video.shape} *Frames x Height x Width x Channel\")\n",
    "print(f\"- Maximum Intensity: {video.max()}\")\n",
    "print(f\"- Minimum Intensity: {video.min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contours(morphed):\n",
    "    contours, _ = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "def draw_keypoints(image, keypoints):\n",
    "    for point in keypoints:\n",
    "        cv2.circle(image, point, 5, (0, 0, 255), -1)\n",
    "    return image\n",
    "\n",
    "def detect_hip_position(contours):\n",
    "    keypoints = []\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 1000:  # 작은 윤곽선 무시\n",
    "            M = cv2.moments(contour)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                keypoints.append((cX, cY))\n",
    "    \n",
    "    if len(keypoints) > 0:\n",
    "        keypoints = sorted(keypoints, key=lambda k: k[1])  # y좌표 기준 정렬\n",
    "        hip = keypoints[len(keypoints) // 2]  # 중간 값이 엉덩이\n",
    "        return hip\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_bounding_boxes(frame, contours, min_width, max_width, min_height, max_height):\n",
    "    bounding_boxes = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if min_width <= w <= max_width and min_height <= h <= max_height:\n",
    "            bounding_boxes.append((x, y, w, h))\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    return frame, bounding_boxes\n",
    "\n",
    "\n",
    "def binarize_image(image, threshold=127):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n",
    "    return binary\n",
    "\n",
    "def count_white_pixels(edge_image):\n",
    "    return np.sum(edge_image == 255)\n",
    "\n",
    "def calculate_frame_difference(frame1, frame2):\n",
    "    diff = cv2.absdiff(frame1, frame2)\n",
    "    binary_diff = binarize_image(diff)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    morphed = cv2.morphologyEx(binary_diff, cv2.MORPH_ERODE, kernel, iterations=1)\n",
    "    return morphed, count_white_pixels(binary_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자세 교정!\n",
      "2210\n",
      "1450\n",
      "0\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 영상 읽기\n",
    "cap = cv2.VideoCapture('plank_sample2.mp4')\n",
    "\n",
    "# 타이머 초기화\n",
    "timer_running = False\n",
    "start_time = 0\n",
    "elapsed_time = 0\n",
    "\n",
    "# 흰색 픽셀 임계값 설정\n",
    "white_pixel_threshold = 30\n",
    "\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "frame_count = 0\n",
    "_, prev_frame = cap.read()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    h, w, c = frame.shape\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.medianBlur(gray, 3)\n",
    "    fg_mask = bg_subtractor.apply(blurred)\n",
    "    _, binary = cv2.threshold(fg_mask, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # morphology 연산\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    morphed = cv2.morphologyEx(binary, cv2.MORPH_ERODE, kernel, iterations=1)\n",
    "    # morphed = cv2.morphologyEx(morphed, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "    if frame_count % 50 == 0:\n",
    "        edges_diff, white_pixel_count = calculate_frame_difference(prev_frame, frame)\n",
    "            \n",
    "        # 타이머 상태 제어\n",
    "        if white_pixel_count > 2000:\n",
    "            print(\"자세 교정!\")\n",
    "        else:\n",
    "            prev_frame = frame.copy()\n",
    "        \n",
    "        # 차분 이미지를 별도로 표시\n",
    "        cv2.imshow('Frame Difference', edges_diff)\n",
    "        print(white_pixel_count)\n",
    "        \n",
    "\n",
    "    # Canny 엣지 검출\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "    # 흰색 픽셀 개수 세기\n",
    "    white_pixel_count = np.sum(morphed == 255)\n",
    "    \n",
    "    \n",
    "    # 타이머 상태 제어\n",
    "    if white_pixel_count > white_pixel_threshold:\n",
    "        if timer_running:\n",
    "            # 타이머 멈춤\n",
    "            elapsed_time += time.time() - start_time\n",
    "            timer_running = False\n",
    "    else:\n",
    "        if not timer_running:\n",
    "            # 타이머 작동\n",
    "            start_time = time.time()\n",
    "            timer_running = True\n",
    "    \n",
    "    # 현재 타이머 상태 표시\n",
    "    if timer_running:\n",
    "        current_time = time.time()\n",
    "        display_time = elapsed_time + (current_time - start_time)\n",
    "    else:\n",
    "        display_time = elapsed_time\n",
    "    \n",
    "    # 타이머 표시\n",
    "    cv2.putText(frame, f'Timer: {display_time:.2f} seconds', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0) if timer_running else (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "    # cv2.imshow('Plank Pose Monitoring', binary[h//3:, w*2//5:w*3//5])\n",
    "    cv2.imshow('Plank Pose Monitoring2', frame)\n",
    "    # cv2.imshow('Plank Pose Monitoring', morphed)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
