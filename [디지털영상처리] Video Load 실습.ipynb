{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad8b815",
   "metadata": {},
   "source": [
    "## Video Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3a1477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n",
    "# !pip install matplotlib==3.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d94b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7b6bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path, ms=100):\n",
    "    \n",
    "    # Video Capture 객체 생성\n",
    "    capture = cv2.VideoCapture(path)\n",
    "    \n",
    "    # Frame을 저장할 List 선언\n",
    "    frames = []\n",
    "    \n",
    "    while capture.isOpened(): # Video Capture가 준비되었는지 확인\n",
    "        \n",
    "        run, frame = capture.read() # 다음 Frame 읽기\n",
    "        \n",
    "        if run: # Frame을 읽은 경우\n",
    "            cv2.imshow(\"video\", frame)\n",
    "            if cv2.waitKey(ms) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else: # 재생이 완료되어 더 이상 Frame을 읽을 수 없는 경우\n",
    "            break\n",
    "        \n",
    "        # Frame List에 추가\n",
    "        frames.append(frame)\n",
    "\n",
    "    capture.release() # Capture 자원 반납\n",
    "    cv2.destroyAllWindows() # 창 제거\n",
    "    \n",
    "    return np.array(frames, dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ad920ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video가 저장된 경로 입력\n",
    "PATH = r\".\\pushup_sample.mp4\"\n",
    "# PATH = r\"C:\\Users\\admin\\Desktop\\KUDIP\\Video Samples\\Hand Video2.mov\"\n",
    "# PATH = r\"C:\\Users\\hj\\AICV\\수업\\디지털영상처리\\Video Samples\\highway.mov\"\n",
    "# PATH = r\"C:\\Users\\hj\\AICV\\수업\\디지털영상처리\\Video Samples\\earth.avi\"\n",
    "\n",
    "# Video 재생 및 반환 (Numpy Array)\n",
    "video = load_video(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42987dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Data Type: <class 'numpy.ndarray'>\n",
      "- Data Shape: (21, 360, 640, 3) *Frames x Height x Width x Channel\n",
      "- Maximum Intensity: 189\n",
      "- Minimum Intensity: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"- Data Type: {type(video)}\")\n",
    "print(f\"- Data Shape: {video.shape} *Frames x Height x Width x Channel\")\n",
    "if video.size > 0:\n",
    "    print(f\"- Maximum Intensity: {video.max()}\")\n",
    "    print(f\"- Minimum Intensity: {video.min()}\")\n",
    "else:\n",
    "    print(\"The array is empty, so maximum and minimum intensities cannot be determined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e35c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 640)\n",
      "(360, 640, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 231\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    230\u001b[0m     video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpushup_sample.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 231\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 209\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(video_path)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# Convert frames to grayscale\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# curr_gray = cv2.cvtColor(cur_frame, cv2.COLOR_BGR2GRAY)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    204\u001b[0m \n\u001b[0;32m    205\u001b[0m \u001b[38;5;66;03m# 결과 이미지 출력\u001b[39;00m\n\u001b[0;32m    206\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOriginal+high boosted\u001b[39m\u001b[38;5;124m'\u001b[39m, cur_frame)\n\u001b[1;32m--> 209\u001b[0m y_position \u001b[38;5;241m=\u001b[39m \u001b[43mget_ground\u001b[49m\u001b[43m(\u001b[49m\u001b[43mskin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_position)\n\u001b[0;32m    211\u001b[0m kernel \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mgetStructuringElement(cv2\u001b[38;5;241m.\u001b[39mMORPH_ELLIPSE, (\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m9\u001b[39m))\n",
      "Cell \u001b[1;32mIn[1], line 137\u001b[0m, in \u001b[0;36mget_ground\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_ground\u001b[39m(image):\n\u001b[1;32m--> 137\u001b[0m     height, width \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(height\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    140\u001b[0m         count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def calculate_circularity(contour):\n",
    "    area = cv2.contourArea(contour)\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    circularity = (4 * np.pi * area) / (perimeter ** 2)\n",
    "    return circularity\n",
    "\n",
    "def find_largest_circularity_contour(contours):\n",
    "    max_circularity = -1\n",
    "    largest_contour = None\n",
    "    \n",
    "    for contour in contours:\n",
    "        circularity = calculate_circularity(contour)\n",
    "        if circularity > max_circularity:\n",
    "            max_circularity = circularity\n",
    "            largest_contour = contour\n",
    "    \n",
    "    return largest_contour\n",
    "\n",
    "def find_center_of_contour(contour):\n",
    "    ((x, y), _radius) = cv2.minEnclosingCircle(contour)\n",
    "    center = (int(x), int(y))\n",
    "    return center\n",
    "\n",
    "def high_boost_filtering(image, alpha=2, kernel_size=(3, 3)):\n",
    "    # Apply low-pass filtering (blur)\n",
    "    blurred = cv2.GaussianBlur(image, kernel_size, 0)\n",
    "    \n",
    "    # Compute high-pass filtered image\n",
    "    high_pass = image - blurred\n",
    "    \n",
    "    # Apply high-boost filtering\n",
    "    high_boosted = image + alpha * high_pass\n",
    "    \n",
    "    # Clip values to ensure they are within the valid range [0, 255]\n",
    "    high_boosted = np.clip(high_boosted, 0, 255)\n",
    "    \n",
    "    return high_boosted.astype(np.uint8)\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    intensity = hsv[:, :, 2]\n",
    "\n",
    "    boosted = high_boost_filtering(intensity)\n",
    "\n",
    "    # 원형 커널 정의 (반지름 5)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    opening = cv2.morphologyEx(boosted, cv2.MORPH_DILATE, kernel)\n",
    "\n",
    "    hsv[:, :, 2] = opening\n",
    "    result = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    return result\n",
    "\n",
    "def three_step_search(prev_frame, curr_frame, search_range=15):\n",
    "    # Get the shape of the frame\n",
    "    height, width = prev_frame.shape[:2]\n",
    "    \n",
    "    # Initialize motion vector\n",
    "    motion_vector = np.zeros(2, dtype=np.uint8)\n",
    "    \n",
    "    # Divide the frame into blocks and initialize initial search point\n",
    "    block_size = 16\n",
    "    x, y = width // 2, height // 2\n",
    "    \n",
    "    # Calculate the initial block and search area\n",
    "    prev_block = prev_frame[y-block_size//2:y+block_size//2, x-block_size//2:x+block_size//2]\n",
    "    search_area = curr_frame[max(0, y-search_range):min(height, y+search_range),\n",
    "                             max(0, x-search_range):min(width, x+search_range)]\n",
    "    \n",
    "    # Search for the best match in the search area\n",
    "    min_sad = float('inf')\n",
    "    for dy in range(-search_range, search_range+1, 3):\n",
    "        for dx in range(-search_range, search_range+1, 3):\n",
    "            if y+dy-block_size//2 < 0 or y+dy+block_size//2 >= height or x+dx-block_size//2 < 0 or x+dx+block_size//2 >= width:\n",
    "                continue\n",
    "            \n",
    "            curr_block = curr_frame[y+dy-block_size//2:y+dy+block_size//2, x+dx-block_size//2:x+dx+block_size//2]\n",
    "            sad = np.sum(np.abs(prev_block.astype(np.uint8) - curr_block.astype(np.uint8)))\n",
    "            \n",
    "            if sad < min_sad:\n",
    "                min_sad = sad\n",
    "                motion_vector[0] = dx\n",
    "                motion_vector[1] = dy\n",
    "    \n",
    "    return motion_vector\n",
    "\n",
    "\n",
    "def count_pushups(head_positions):\n",
    "    count = 0\n",
    "    state = 0  # 0: 시작, 1: 내려감, 2: 올라옴\n",
    "    for i in range(1, len(head_positions)):\n",
    "        if head_positions[i-1] is None or head_positions[i] is None:\n",
    "            continue\n",
    "        if state == 0 and head_positions[i][1] > head_positions[i-1][1]:\n",
    "            state = 1\n",
    "        elif state == 1 and head_positions[i][1] < head_positions[i-1][1]:\n",
    "            count += 1\n",
    "            state = 2\n",
    "        elif state == 2 and head_positions[i][1] > head_positions[i-1][1]:\n",
    "            state = 1\n",
    "    return count\n",
    "\n",
    "def detect_skin(img):\n",
    "\n",
    "    #converting from gbr to hsv color space\n",
    "    img_HSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    #skin color range for hsv color space \n",
    "    HSV_mask = cv2.inRange(img_HSV, (0, 15, 0), (17,170,255)) \n",
    "\n",
    "    HSV_mask = cv2.morphologyEx(HSV_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "\n",
    "    #converting from gbr to YCbCr color space\n",
    "    img_YCrCb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    #skin color range for hsv color space \n",
    "    YCrCb_mask = cv2.inRange(img_YCrCb, (0, 135, 85), (255,180,135)) \n",
    "    YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "\n",
    "    #merge skin detection (YCbCr and hsv)\n",
    "    global_mask=cv2.bitwise_and(YCrCb_mask,HSV_mask)\n",
    "    global_mask=cv2.medianBlur(global_mask, 5)\n",
    "    global_mask = cv2.morphologyEx(global_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "\n",
    "\n",
    "    HSV_result = cv2.bitwise_not(HSV_mask)\n",
    "    YCrCb_result = cv2.bitwise_not(YCrCb_mask)\n",
    "    global_result=cv2.bitwise_not(global_mask)\n",
    "    print(global_mask.shape)\n",
    "\n",
    "    return global_mask\n",
    "\n",
    "def get_ground(image):\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    for y in range(height-1, -1, -1):\n",
    "        count = 0\n",
    "        for x in range(width):\n",
    "            if image[y, x] == 255:\n",
    "                count += 1\n",
    "                if count >= 10:\n",
    "                    return y  # Return the position of the first continuous 1s\n",
    "            else:\n",
    "                count = 0\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def main(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, prev_frame = cap.read()\n",
    "    head_positions = []\n",
    "    frames = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, cur_frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        cur_frame = preprocess_frame(cur_frame)\n",
    "\n",
    "        # circles = cv2.HoughCircles(cur_frame_gray, cv2.HOUGH_GRADIENT, 1, cur_frame_gray.shape[0]/8,\n",
    "        #                     param1=100, param2=30, minRadius=1, maxRadius=20)\n",
    "\n",
    "        # circles = np.uint16(np.around(circles))\n",
    "        # for i in circles[0,:]:\n",
    "        #     # draw the outer circle\n",
    "        #     cv2.circle(cur_frame,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "        #     # draw the center of the circle\n",
    "        #     cv2.circle(cur_frame,(i[0],i[1]),2,(0,0,255),3)\n",
    "\n",
    "\n",
    "        # 피부색 검출\n",
    "        skin_mask = detect_skin(cur_frame)\n",
    "        cur_frame_hsv = cv2.cvtColor(cur_frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        v = cur_frame_hsv[:, :, 2]\n",
    "        masked_v = cv2.bitwise_and(v, skin_mask)\n",
    "        cur_frame_hsv[:, :, 2] = masked_v\n",
    "        skin = cv2.cvtColor(cur_frame_hsv, cv2.COLOR_HSV2BGR)\n",
    "        print(skin.shape)\n",
    "        # Convert frames to grayscale\n",
    "        # prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        # curr_gray = cv2.cvtColor(cur_frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Estimate motion vector using 3 step search\n",
    "        # motion_vector = three_step_search(prev_gray, curr_gray)\n",
    "        \n",
    "        # Update the position\n",
    "        # x, y = prev_frame.shape[1] // 2, prev_frame.shape[0] // 2\n",
    "        # x += motion_vector[0]\n",
    "        # y += motion_vector[1]\n",
    "        \n",
    "        # # Draw a rectangle around the detected object\n",
    "        # cv2.rectangle(prev_frame, (x-8, y-8), (x+8, y+8), (0, 255, 0), 2)\n",
    "        \n",
    "        # # Display the result\n",
    "        # cv2.imshow('Result', prev_frame)\n",
    "\n",
    "\n",
    "        # 결과 이미지 출력\n",
    "        cv2.imshow('Original+high boosted', cur_frame)\n",
    "\n",
    "\n",
    "        y_position = get_ground(skin)\n",
    "        print(y_position)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))\n",
    "        skin = cv2.morphologyEx(skin, cv2.MORPH_CLOSE, kernel)\n",
    "        cv2.line(skin, (0, y_position), (skin.shape[1], y_position), (0, 0, 255), 2)\n",
    "        cv2.imshow('skin detection + draw circle_9', skin)\n",
    "\n",
    "        # Update the previous frame\n",
    "        prev_frame = cur_frame.copy()\n",
    "\n",
    "        frames.append(cur_frame)\n",
    "        if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    pushup_count = count_pushups(head_positions)\n",
    "    print(f\"Total push-ups: {pushup_count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"pushup_sample.mp4\"\n",
    "    main(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27543fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1dbd1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
