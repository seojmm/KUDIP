{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path, ms=100):\n",
    "    \n",
    "    # Video Capture 객체 생성\n",
    "    capture = cv2.VideoCapture(path)\n",
    "    \n",
    "    # Frame을 저장할 List 선언\n",
    "    frames = []\n",
    "    \n",
    "    while capture.isOpened(): # Video Capture가 준비되었는지 확인\n",
    "        \n",
    "        run, frame = capture.read() # 다음 Frame 읽기\n",
    "        # ROI 설정 (x, y, width, height)\n",
    "        roi_x, roi_y, roi_w, roi_h = 0, 280, 852, 200\n",
    "        \n",
    "        # ROI 추출\n",
    "        roi = frame[roi_y:roi_y + roi_h, roi_x:roi_x + roi_w]\n",
    "\n",
    "        # 그레이스케일 변환\n",
    "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        edges = cv2.Canny(blurred, 50, 150)\n",
    "        # 원본 프레임에 엣지 결과를 덮어쓰기 (ROI 영역만)\n",
    "        frame[roi_y:roi_y + roi_h, roi_x:roi_x + roi_w] = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        \n",
    "        if run: # Frame을 읽은 경우\n",
    "            # 결과 출력\n",
    "            cv2.imshow('Frame with ROI Edges', frame)\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else: # 재생이 완료되어 더 이상 Frame을 읽을 수 없는 경우\n",
    "            break\n",
    "        \n",
    "        # Frame List에 추가\n",
    "        frames.append(frame)\n",
    "\n",
    "    capture.release() # Capture 자원 반납\n",
    "    cv2.destroyAllWindows() # 창 제거\n",
    "    \n",
    "    return np.array(frames, dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video가 저장된 경로 입력\n",
    "PATH = r\".\\plank_sample2.mp4\"\n",
    "# PATH = r\"C:\\Users\\admin\\Desktop\\KUDIP\\Video Samples\\Hand Video2.mov\"\n",
    "# PATH = r\"C:\\Users\\hj\\AICV\\수업\\디지털영상처리\\Video Samples\\highway.mov\"\n",
    "# PATH = r\"C:\\Users\\hj\\AICV\\수업\\디지털영상처리\\Video Samples\\earth.avi\"\n",
    "\n",
    "# Video 재생 및 반환 (Numpy Array)\n",
    "video = load_video(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Data Type: <class 'numpy.ndarray'>\n",
      "- Data Shape: (201, 480, 852, 3) *Frames x Height x Width x Channel\n",
      "- Maximum Intensity: 255\n",
      "- Minimum Intensity: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"- Data Type: {type(video)}\")\n",
    "print(f\"- Data Shape: {video.shape} *Frames x Height x Width x Channel\")\n",
    "print(f\"- Maximum Intensity: {video.max()}\")\n",
    "print(f\"- Minimum Intensity: {video.min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contours(morphed):\n",
    "    contours, _ = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "def draw_keypoints(image, keypoints):\n",
    "    for point in keypoints:\n",
    "        cv2.circle(image, point, 5, (0, 0, 255), -1)\n",
    "    return image\n",
    "\n",
    "def detect_hip_position(contours):\n",
    "    keypoints = []\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 1000:  # 작은 윤곽선 무시\n",
    "            M = cv2.moments(contour)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                keypoints.append((cX, cY))\n",
    "    \n",
    "    if len(keypoints) > 0:\n",
    "        keypoints = sorted(keypoints, key=lambda k: k[1])  # y좌표 기준 정렬\n",
    "        hip = keypoints[len(keypoints) // 2]  # 중간 값이 엉덩이\n",
    "        return hip\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(429, 172)\n",
      "(261, 351)\n",
      "(353, 361)\n",
      "(352, 360)\n",
      "(266, 367)\n",
      "(552, 409)\n",
      "(554, 402)\n",
      "(567, 394)\n",
      "(576, 393)\n",
      "(585, 391)\n",
      "(248, 396)\n",
      "(481, 406)\n",
      "(610, 403)\n",
      "(610, 403)\n",
      "(611, 407)\n",
      "(248, 409)\n",
      "(248, 408)\n",
      "(609, 419)\n",
      "(609, 420)\n",
      "(610, 408)\n",
      "(609, 408)\n",
      "(610, 409)\n",
      "(615, 425)\n",
      "(549, 425)\n",
      "(518, 425)\n",
      "(518, 424)\n",
      "(510, 418)\n",
      "(506, 418)\n",
      "(596, 395)\n",
      "(596, 394)\n",
      "(520, 414)\n",
      "(569, 387)\n",
      "(465, 415)\n",
      "(220, 392)\n",
      "(219, 386)\n",
      "(569, 381)\n",
      "(569, 381)\n",
      "(217, 385)\n",
      "(614, 411)\n",
      "(615, 415)\n",
      "(615, 415)\n",
      "(613, 409)\n",
      "(618, 407)\n",
      "(606, 410)\n",
      "(606, 410)\n",
      "(605, 408)\n",
      "(608, 406)\n",
      "(613, 422)\n",
      "(613, 432)\n",
      "(613, 432)\n",
      "(613, 431)\n",
      "(613, 428)\n",
      "(614, 431)\n",
      "(614, 428)\n",
      "(378, 359)\n",
      "(378, 358)\n",
      "(375, 358)\n",
      "(374, 358)\n",
      "(616, 430)\n",
      "(616, 430)\n",
      "(616, 430)\n",
      "(616, 430)\n",
      "(618, 428)\n",
      "(618, 424)\n",
      "(619, 415)\n",
      "(623, 413)\n",
      "(625, 414)\n",
      "(393, 339)\n",
      "(223, 364)\n",
      "(223, 362)\n",
      "(223, 363)\n",
      "(223, 363)\n",
      "(224, 362)\n",
      "(223, 363)\n",
      "(223, 363)\n",
      "(223, 363)\n",
      "(224, 362)\n",
      "(224, 363)\n",
      "(225, 363)\n",
      "(225, 363)\n",
      "(222, 365)\n",
      "(222, 365)\n",
      "(229, 361)\n",
      "(230, 362)\n",
      "(224, 363)\n",
      "(223, 363)\n",
      "(222, 360)\n",
      "(222, 360)\n",
      "(222, 359)\n",
      "(228, 361)\n",
      "(228, 361)\n",
      "(336, 373)\n",
      "(415, 382)\n",
      "(416, 380)\n",
      "(416, 380)\n",
      "(388, 365)\n",
      "(245, 383)\n",
      "(243, 382)\n",
      "(242, 385)\n",
      "(242, 382)\n",
      "(609, 421)\n",
      "(534, 393)\n",
      "(608, 425)\n",
      "(459, 378)\n",
      "(452, 378)\n",
      "(453, 378)\n",
      "(454, 381)\n",
      "(461, 387)\n",
      "(458, 390)\n",
      "(458, 390)\n",
      "(496, 452)\n",
      "(464, 392)\n",
      "(464, 393)\n",
      "(457, 399)\n",
      "(450, 401)\n",
      "(450, 401)\n",
      "(449, 400)\n",
      "(445, 401)\n",
      "(445, 402)\n",
      "(444, 401)\n",
      "(444, 401)\n",
      "(443, 400)\n",
      "(444, 399)\n",
      "(453, 402)\n",
      "(453, 402)\n",
      "(456, 400)\n",
      "(458, 401)\n",
      "(227, 369)\n",
      "(499, 431)\n",
      "(458, 407)\n",
      "(458, 407)\n",
      "(458, 409)\n",
      "(457, 409)\n",
      "(461, 410)\n",
      "(463, 411)\n",
      "(463, 411)\n",
      "(462, 412)\n",
      "(440, 408)\n",
      "(429, 407)\n",
      "(429, 407)\n",
      "(427, 407)\n",
      "(426, 409)\n",
      "(422, 408)\n",
      "(420, 409)\n",
      "(413, 409)\n",
      "(412, 409)\n",
      "(414, 411)\n",
      "(412, 411)\n",
      "(411, 411)\n",
      "(410, 411)\n",
      "(410, 411)\n",
      "(410, 409)\n",
      "(412, 409)\n",
      "(406, 408)\n",
      "(406, 408)\n",
      "(404, 404)\n",
      "(405, 401)\n",
      "(404, 398)\n",
      "(403, 397)\n",
      "(403, 396)\n",
      "(403, 396)\n",
      "(401, 396)\n",
      "(296, 204)\n",
      "(409, 339)\n",
      "(414, 339)\n",
      "(414, 338)\n",
      "(411, 338)\n",
      "(411, 337)\n",
      "(412, 336)\n",
      "(412, 336)\n",
      "(419, 329)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 영상 읽기\n",
    "cap = cv2.VideoCapture('plank_sample2.mp4')\n",
    "\n",
    "# 타이머 설정\n",
    "total_time = 0\n",
    "start_time = cv2.getTickCount()\n",
    "stop_timer = False\n",
    "\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    h, w, c = frame.shape\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.medianBlur(gray, 3)\n",
    "    fg_mask = bg_subtractor.apply(blurred)\n",
    "    _, binary = cv2.threshold(fg_mask, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # morphology 연산\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    morphed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    morphed = cv2.morphologyEx(morphed, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    \n",
    "    contours = find_contours(morphed)\n",
    "    hip_position = detect_hip_position(contours)\n",
    "    if hip_position:\n",
    "        print(hip_position)\n",
    "    # Canny 엣지 검출\n",
    "    # edges = cv2.Canny(blurred, 50, 150)\n",
    "    \n",
    "\n",
    "    cv2.imshow('Plank Pose Monitoring', binary[:, w*2//5:w*3//5])\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
