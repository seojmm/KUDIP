{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad8b815",
   "metadata": {},
   "source": [
    "## Video Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b3a1477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n",
    "# !pip install matplotlib==3.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d94b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7b6bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path, ms=100):\n",
    "    \n",
    "    # Video Capture 객체 생성\n",
    "    capture = cv2.VideoCapture(path)\n",
    "    \n",
    "    # Frame을 저장할 List 선언\n",
    "    frames = []\n",
    "    \n",
    "    while capture.isOpened(): # Video Capture가 준비되었는지 확인\n",
    "        \n",
    "        run, frame = capture.read() # 다음 Frame 읽기\n",
    "        \n",
    "        if run: # Frame을 읽은 경우\n",
    "            cv2.imshow(\"video\", frame)\n",
    "            if cv2.waitKey(ms) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else: # 재생이 완료되어 더 이상 Frame을 읽을 수 없는 경우\n",
    "            break\n",
    "        \n",
    "        # Frame List에 추가\n",
    "        frames.append(frame)\n",
    "\n",
    "    capture.release() # Capture 자원 반납\n",
    "    cv2.destroyAllWindows() # 창 제거\n",
    "    \n",
    "    return np.array(frames, dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ad920ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video가 저장된 경로 입력\n",
    "PATH = r\".\\pushup_sample.mp4\"\n",
    "# PATH = r\"C:\\Users\\admin\\Desktop\\KUDIP\\Video Samples\\Hand Video2.mov\"\n",
    "# PATH = r\"C:\\Users\\hj\\AICV\\수업\\디지털영상처리\\Video Samples\\highway.mov\"\n",
    "# PATH = r\"C:\\Users\\hj\\AICV\\수업\\디지털영상처리\\Video Samples\\earth.avi\"\n",
    "\n",
    "# Video 재생 및 반환 (Numpy Array)\n",
    "video = load_video(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42987dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Data Type: <class 'numpy.ndarray'>\n",
      "- Data Shape: (12, 360, 640, 3) *Frames x Height x Width x Channel\n",
      "- Maximum Intensity: 97\n",
      "- Minimum Intensity: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"- Data Type: {type(video)}\")\n",
    "print(f\"- Data Shape: {video.shape} *Frames x Height x Width x Channel\")\n",
    "if video.size > 0:\n",
    "    print(f\"- Maximum Intensity: {video.max()}\")\n",
    "    print(f\"- Minimum Intensity: {video.min()}\")\n",
    "else:\n",
    "    print(\"The array is empty, so maximum and minimum intensities cannot be determined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b51e35c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def calculate_circularity(contour):\n",
    "    area = cv2.contourArea(contour)\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    circularity = (4 * np.pi * area) / (perimeter ** 2)\n",
    "    return circularity\n",
    "\n",
    "def find_largest_circularity_contour(contours):\n",
    "    max_circularity = -1\n",
    "    largest_contour = None\n",
    "    \n",
    "    for contour in contours:\n",
    "        circularity = calculate_circularity(contour)\n",
    "        if circularity > max_circularity:\n",
    "            max_circularity = circularity\n",
    "            largest_contour = contour\n",
    "    \n",
    "    return largest_contour\n",
    "\n",
    "def find_center_of_contour(contour):\n",
    "    ((x, y), _radius) = cv2.minEnclosingCircle(contour)\n",
    "    center = (int(x), int(y))\n",
    "    return center\n",
    "\n",
    "def high_boost_filter(image, kernel_size=3, k=1.2):\n",
    "    \"\"\"\n",
    "    이미지에 High Boost Filtering을 적용합니다.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): 입력 이미지\n",
    "        kernel_size (int): 커널 크기 (기본값은 3)\n",
    "        k (float): High Boost 계수 (기본값은 1.2)\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: High Boost Filtering된 이미지\n",
    "    \"\"\"\n",
    "    # 평균 필터링을 통해 저주파 성분 추출\n",
    "    blur = cv2.blur(image, (kernel_size, kernel_size))\n",
    "\n",
    "    # High Boost Filtering 적용\n",
    "    high_boost_image = image * k - blur\n",
    "\n",
    "    # 결과 이미지 반환\n",
    "    return high_boost_image\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    intensity = hsv[:, :, 2]\n",
    "\n",
    "    # boosted = high_boost_filter(intensity)\n",
    "\n",
    "    # 원형 커널 정의 (반지름 5)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    opening = cv2.morphologyEx(intensity, cv2.MORPH_DILATE, kernel)\n",
    "\n",
    "    hsv[:, :, 2] = opening\n",
    "    result = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def count_pushups(head_positions):\n",
    "    count = 0\n",
    "    state = 0  # 0: 시작, 1: 내려감, 2: 올라옴\n",
    "    for i in range(1, len(head_positions)):\n",
    "        if head_positions[i-1] is None or head_positions[i] is None:\n",
    "            continue\n",
    "        if state == 0 and head_positions[i][1] > head_positions[i-1][1]:\n",
    "            state = 1\n",
    "        elif state == 1 and head_positions[i][1] < head_positions[i-1][1]:\n",
    "            count += 1\n",
    "            state = 2\n",
    "        elif state == 2 and head_positions[i][1] > head_positions[i-1][1]:\n",
    "            state = 1\n",
    "    return count\n",
    "\n",
    "def detect_skin(img):\n",
    "\n",
    "    #converting from gbr to hsv color space\n",
    "    img_HSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    #skin color range for hsv color space \n",
    "    HSV_mask = cv2.inRange(img_HSV, (0, 15, 0), (17,170,255)) \n",
    "\n",
    "    HSV_mask = cv2.morphologyEx(HSV_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "\n",
    "    #converting from gbr to YCbCr color space\n",
    "    img_YCrCb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    #skin color range for hsv color space \n",
    "    YCrCb_mask = cv2.inRange(img_YCrCb, (0, 135, 85), (255,180,135)) \n",
    "    YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "\n",
    "    #merge skin detection (YCbCr and hsv)\n",
    "    global_mask=cv2.bitwise_and(YCrCb_mask,HSV_mask)\n",
    "    global_mask=cv2.medianBlur(global_mask, 5)\n",
    "    global_mask = cv2.morphologyEx(global_mask, cv2.MORPH_OPEN, np.ones((7,7), np.uint8))\n",
    "\n",
    "\n",
    "    HSV_result = cv2.bitwise_not(HSV_mask)\n",
    "    YCrCb_result = cv2.bitwise_not(YCrCb_mask)\n",
    "    global_result=cv2.bitwise_not(global_mask)\n",
    "\n",
    "    return global_mask\n",
    "\n",
    "def get_ground(image):\n",
    "    height, width = image.shape\n",
    "\n",
    "    for y in range(height-1, -1, -1):\n",
    "        count = 0\n",
    "        for x in range(width):\n",
    "            if image[y, x] == 255:\n",
    "                count += 1\n",
    "                if count >= 10:\n",
    "                    return y  # Return the position of the first continuous 1s\n",
    "            else:\n",
    "                count = 0\n",
    "    \n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "27543fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def three_step_search(prev_frame, curr_frame, block_size=16, search_range=7):\n",
    "    \"\"\"\n",
    "    3 단계 탐색 알고리즘을 사용하여 모션 벡터를 계산합니다.\n",
    "\n",
    "    Args:\n",
    "        prev_frame (numpy.ndarray): 이전 프레임\n",
    "        curr_frame (numpy.ndarray): 현재 프레임\n",
    "        block_size (int): 블록 크기 (기본값은 16)\n",
    "        search_range (int): 탐색 범위 (기본값은 7)\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: 모션 벡터 배열\n",
    "    \"\"\"\n",
    "    height, width = prev_frame.shape[:2]\n",
    "    motion_vectors = np.zeros((height // block_size, width // block_size, 2), dtype=np.int32)\n",
    "\n",
    "    for y in range(0, height, block_size):\n",
    "        for x in range(0, width, block_size):\n",
    "            # 이전 프레임의 블록 추출\n",
    "            prev_block = prev_frame[y:y+block_size, x:x+block_size]\n",
    "\n",
    "            # 현재 프레임에서의 최적의 블록 위치 찾기\n",
    "            best_match = None\n",
    "            best_sad = float('inf')\n",
    "\n",
    "            # 1단계: 중심에서 ±search_range 범위 내에서 탐색\n",
    "            for dy in range(-search_range, search_range+1, 2*search_range):\n",
    "                for dx in range(-search_range, search_range+1, 2*search_range):\n",
    "                    curr_y, curr_x = y + dy, x + dx\n",
    "                    if 0 <= curr_y < height-block_size and 0 <= curr_x < width-block_size:\n",
    "                        curr_block = curr_frame[curr_y:curr_y+block_size, curr_x:curr_x+block_size]\n",
    "                        sad = np.sum(np.abs(prev_block - curr_block))\n",
    "                        if sad < best_sad:\n",
    "                            best_sad = sad\n",
    "                            best_match = (dy, dx)\n",
    "\n",
    "            if best_match is None:\n",
    "                return None\n",
    "            # 2단계: 최적 위치에서 ±search_range//2 범위 내에서 탐색\n",
    "            for dy in range(best_match[0]-search_range//2, best_match[0]+search_range//2+1, search_range//2):\n",
    "                for dx in range(best_match[1]-search_range//2, best_match[1]+search_range//2+1, search_range//2):\n",
    "                    curr_y, curr_x = y + dy, x + dx\n",
    "                    if 0 <= curr_y < height-block_size and 0 <= curr_x < width-block_size:\n",
    "                        curr_block = curr_frame[curr_y:curr_y+block_size, curr_x:curr_x+block_size]\n",
    "                        sad = np.sum(np.abs(prev_block - curr_block))\n",
    "                        if sad < best_sad:\n",
    "                            best_sad = sad\n",
    "                            best_match = (dy, dx)\n",
    "\n",
    "            # 3단계: 최적 위치에서 ±1 범위 내에서 탐색\n",
    "            for dy in range(best_match[0]-1, best_match[0]+2, 1):\n",
    "                for dx in range(best_match[1]-1, best_match[1]+2, 1):\n",
    "                    curr_y, curr_x = y + dy, x + dx\n",
    "                    if 0 <= curr_y < height-block_size and 0 <= curr_x < width-block_size:\n",
    "                        curr_block = curr_frame[curr_y:curr_y+block_size, curr_x:curr_x+block_size]\n",
    "                        sad = np.sum(np.abs(prev_block - curr_block))\n",
    "                        if sad < best_sad:\n",
    "                            best_sad = sad\n",
    "                            best_match = (dy, dx)\n",
    "\n",
    "            motion_vectors[y//block_size, x//block_size] = best_match\n",
    "\n",
    "    return motion_vectors\n",
    "\n",
    "def calculate_angle(points):\n",
    "    if len(points) < 2:\n",
    "        return None\n",
    "    # Fit a line to the points\n",
    "    [vx, vy, x, y] = cv2.fitLine(np.array(points), cv2.DIST_L2, 0, 0.01, 0.01)\n",
    "    # Calculate the angle with the horizontal axis\n",
    "    angle = np.arctan2(vy[0], vx[0]) * 180 / np.pi\n",
    "    return angle\n",
    "\n",
    "def draw_flow(img, flow, step=16):\n",
    "    h, w = img.shape[:2]\n",
    "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1)\n",
    "    fx, fy = flow[y, x].T\n",
    "\n",
    "    lines = np.vstack([x, y, x+fx, y+fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "    vis = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    vis = cv2.cvtColor(vis, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.polylines(vis, lines, 0, (0, 255, 0))\n",
    "\n",
    "    for (x1, y1), (x2, y2) in lines:\n",
    "        cv2.circle(vis, (x1, y1), 1, (0, 255, 0), -1)\n",
    "    return vis\n",
    "\n",
    "def get_vertical_motion_coords(flow, threshold=1.0, v_speed=1.0):\n",
    "    h, w = flow.shape[:2]\n",
    "    coords = []\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            if abs(flow[y, x, 1] - v_speed) < threshold:\n",
    "                coords.append((x, y))\n",
    "    return coords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "e2e95fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def main(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    ret, prev_frame = cap.read()\n",
    "    h, w, _ = prev_frame.shape\n",
    "    # prev_frame = prev_frame[h//3:, w//4-20:w*3//4+20]\n",
    "    head_positions = []\n",
    "    frames = []\n",
    "\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        h, w, _ = frame.shape\n",
    "        # frame = frame[h//3:, w//4-20:w*3//4+20]\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        cur_frame = preprocess_frame(frame)\n",
    "        gray = cv2.cvtColor(cur_frame, cv2.COLOR_BGR2GRAY)\n",
    "        _, otsu_threshold = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "        cv2.imshow('otsu', otsu_threshold)\n",
    "\n",
    "        \n",
    "        gray = cv2.cvtColor(cur_frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "\n",
    "        # 배경 차분 수행\n",
    "        fg_mask = bg_subtractor.apply(cur_frame)\n",
    "        \n",
    "        # 객체 추출\n",
    "        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # 움직이는 객체가 사람인지 판단하고 선 그리기\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > 1000:  # 임계값 설정\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                cv2.rectangle(cur_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        edges = cv2.Canny(otsu_threshold, 100, 200)\n",
    "        \n",
    "\n",
    "        # Calculate optical flow\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "        # 수직 방향 모션 벡터 추출\n",
    "        flow_y = flow[..., 1]\n",
    "\n",
    "        # 수직 방향 모션 벡터의 크기 계산\n",
    "        magnitude = np.abs(flow_y)\n",
    "\n",
    "        # 임계값 이상의 크기를 가진 구역 식별\n",
    "        threshold = 12  # 임의의 임계값\n",
    "        motion_region = np.where(magnitude > threshold)\n",
    "\n",
    "        # 각 구역의 중심점 계산\n",
    "        if motion_region[1].size > 0:\n",
    "            x_coords = np.mean(motion_region[1])\n",
    "            cv2.line(cur_frame, (int(x_coords), 0), (int(x_coords), h), (255, 0, 0), thickness=3)\n",
    "\n",
    "        cv2.imshow('edges', edges)\n",
    "        cv2.imshow('Result', cur_frame)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # 이전 프레임 업데이트\n",
    "        prev_gray = gray.copy()\n",
    "\n",
    "        # frames.append(cur_frame)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    pushup_count = count_pushups(head_positions)\n",
    "    print(f\"Total push-ups: {pushup_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "7e1dbd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total push-ups: 0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    video_path = \"pushup_sample.mp4\"\n",
    "    main(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "80d297d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MOG2 배경 제거 모델 생성\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# 영상 읽기\n",
    "cap = cv2.VideoCapture('./pushup_sample.mp4')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # 배경 제거 수행\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    \n",
    "    # 객체 추출\n",
    "    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # 움직이는 객체가 사람인지 판단하고 선 그리기\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 800:  # 임계값 설정\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    # 결과 출력\n",
    "    cv2.imshow('Object Detection', frame)\n",
    "    \n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "dd27bfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 배경 제거 모델 생성\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# 영상 읽기\n",
    "cap = cv2.VideoCapture('./pushup_sample.mp4')\n",
    "\n",
    "# 푸쉬업을 하는 사람 수 초기화\n",
    "pushup_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # 배경 제거 수행\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    \n",
    "    # 객체 추출\n",
    "    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # 푸쉬업을 하는 사람 감지 및 카운트\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 500:  # 임계값 설정\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            \n",
    "            # 푸쉬업을 하는 사람으로 판단하는 추가적인 조건을 여기에 추가할 수 있습니다.\n",
    "            # 예를 들어, 객체의 높이와 가로 세로 비율 등을 고려하여 판단할 수 있습니다.\n",
    "            # 여기서는 간단히 객체의 개수를 세어서 푸쉬업을 하는 사람의 수를 계산합니다.\n",
    "            pushup_count += 1\n",
    "    \n",
    "    # 결과 출력\n",
    "    cv2.putText(frame, f'Pushup Count: {pushup_count}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.imshow('Pushup Detection', frame)\n",
    "    \n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff50804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
