{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad8b815",
   "metadata": {},
   "source": [
    "## Video Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b3a1477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n",
    "# !pip install matplotlib==3.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d94b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7b6bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path, ms=100):\n",
    "    \n",
    "    # Video Capture 객체 생성\n",
    "    capture = cv2.VideoCapture(path)\n",
    "    \n",
    "    # Frame을 저장할 List 선언\n",
    "    frames = []\n",
    "    \n",
    "    while capture.isOpened(): # Video Capture가 준비되었는지 확인\n",
    "        \n",
    "        run, frame = capture.read() # 다음 Frame 읽기\n",
    "        \n",
    "        if run: # Frame을 읽은 경우\n",
    "            cv2.imshow(\"video\", frame)\n",
    "            if cv2.waitKey(ms) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else: # 재생이 완료되어 더 이상 Frame을 읽을 수 없는 경우\n",
    "            break\n",
    "        \n",
    "        # Frame List에 추가\n",
    "        frames.append(frame)\n",
    "\n",
    "    capture.release() # Capture 자원 반납\n",
    "    cv2.destroyAllWindows() # 창 제거\n",
    "    \n",
    "    return np.array(frames, dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ad920ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video가 저장된 경로 입력\n",
    "PATH = r\".\\pushup_sample.mp4\"\n",
    "# PATH = r\"C:\\Users\\admin\\Desktop\\KUDIP\\Video Samples\\Hand Video2.mov\"\n",
    "# PATH = r\"C:\\Users\\hj\\AICV\\수업\\디지털영상처리\\Video Samples\\highway.mov\"\n",
    "# PATH = r\"C:\\Users\\hj\\AICV\\수업\\디지털영상처리\\Video Samples\\earth.avi\"\n",
    "\n",
    "# Video 재생 및 반환 (Numpy Array)\n",
    "video = load_video(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42987dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Data Type: <class 'numpy.ndarray'>\n",
      "- Data Shape: (16, 360, 640, 3) *Frames x Height x Width x Channel\n",
      "- Maximum Intensity: 132\n",
      "- Minimum Intensity: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"- Data Type: {type(video)}\")\n",
    "print(f\"- Data Shape: {video.shape} *Frames x Height x Width x Channel\")\n",
    "if video.size > 0:\n",
    "    print(f\"- Maximum Intensity: {video.max()}\")\n",
    "    print(f\"- Minimum Intensity: {video.min()}\")\n",
    "else:\n",
    "    print(\"The array is empty, so maximum and minimum intensities cannot be determined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b51e35c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def calculate_circularity(contour):\n",
    "    area = cv2.contourArea(contour)\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    circularity = (4 * np.pi * area) / (perimeter ** 2)\n",
    "    return circularity\n",
    "\n",
    "def find_largest_circularity_contour(contours):\n",
    "    max_circularity = -1\n",
    "    largest_contour = None\n",
    "    \n",
    "    for contour in contours:\n",
    "        circularity = calculate_circularity(contour)\n",
    "        if circularity > max_circularity:\n",
    "            max_circularity = circularity\n",
    "            largest_contour = contour\n",
    "    \n",
    "    return largest_contour\n",
    "\n",
    "def find_center_of_contour(contour):\n",
    "    ((x, y), _radius) = cv2.minEnclosingCircle(contour)\n",
    "    center = (int(x), int(y))\n",
    "    return center\n",
    "\n",
    "def high_boost_filter(image, kernel_size=3, k=1.2):\n",
    "    \"\"\"\n",
    "    이미지에 High Boost Filtering을 적용합니다.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): 입력 이미지\n",
    "        kernel_size (int): 커널 크기 (기본값은 3)\n",
    "        k (float): High Boost 계수 (기본값은 1.2)\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: High Boost Filtering된 이미지\n",
    "    \"\"\"\n",
    "    # 평균 필터링을 통해 저주파 성분 추출\n",
    "    blur = cv2.blur(image, (kernel_size, kernel_size))\n",
    "\n",
    "    # High Boost Filtering 적용\n",
    "    high_boost_image = image * k - blur\n",
    "\n",
    "    # 결과 이미지 반환\n",
    "    return high_boost_image\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    intensity = hsv[:, :, 2]\n",
    "\n",
    "    # boosted = high_boost_filter(intensity)\n",
    "\n",
    "    # 원형 커널 정의 (반지름 5)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    opening = cv2.morphologyEx(intensity, cv2.MORPH_DILATE, kernel)\n",
    "\n",
    "    hsv[:, :, 2] = opening\n",
    "    result = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def count_pushups(head_positions):\n",
    "    count = 0\n",
    "    state = 0  # 0: 시작, 1: 내려감, 2: 올라옴\n",
    "    for i in range(1, len(head_positions)):\n",
    "        if head_positions[i-1] is None or head_positions[i] is None:\n",
    "            continue\n",
    "        if state == 0 and head_positions[i][1] > head_positions[i-1][1]:\n",
    "            state = 1\n",
    "        elif state == 1 and head_positions[i][1] < head_positions[i-1][1]:\n",
    "            count += 1\n",
    "            state = 2\n",
    "        elif state == 2 and head_positions[i][1] > head_positions[i-1][1]:\n",
    "            state = 1\n",
    "    return count\n",
    "\n",
    "def detect_skin(img):\n",
    "\n",
    "    #converting from gbr to hsv color space\n",
    "    img_HSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    #skin color range for hsv color space \n",
    "    HSV_mask = cv2.inRange(img_HSV, (0, 15, 0), (17,170,255)) \n",
    "\n",
    "    HSV_mask = cv2.morphologyEx(HSV_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "\n",
    "    #converting from gbr to YCbCr color space\n",
    "    img_YCrCb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    #skin color range for hsv color space \n",
    "    YCrCb_mask = cv2.inRange(img_YCrCb, (0, 135, 85), (255,180,135)) \n",
    "    YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "\n",
    "    #merge skin detection (YCbCr and hsv)\n",
    "    global_mask=cv2.bitwise_and(YCrCb_mask,HSV_mask)\n",
    "    global_mask=cv2.medianBlur(global_mask, 5)\n",
    "    global_mask = cv2.morphologyEx(global_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "\n",
    "\n",
    "    HSV_result = cv2.bitwise_not(HSV_mask)\n",
    "    YCrCb_result = cv2.bitwise_not(YCrCb_mask)\n",
    "    global_result=cv2.bitwise_not(global_mask)\n",
    "\n",
    "    return global_mask\n",
    "\n",
    "def get_ground(image):\n",
    "    height, width = image.shape\n",
    "\n",
    "    for y in range(height-1, -1, -1):\n",
    "        count = 0\n",
    "        for x in range(width):\n",
    "            if image[y, x] == 255:\n",
    "                count += 1\n",
    "                if count >= 10:\n",
    "                    return y  # Return the position of the first continuous 1s\n",
    "            else:\n",
    "                count = 0\n",
    "    \n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27543fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def three_step_search(prev_frame, curr_frame, block_size=16, search_range=7):\n",
    "    \"\"\"\n",
    "    3 단계 탐색 알고리즘을 사용하여 모션 벡터를 계산합니다.\n",
    "\n",
    "    Args:\n",
    "        prev_frame (numpy.ndarray): 이전 프레임\n",
    "        curr_frame (numpy.ndarray): 현재 프레임\n",
    "        block_size (int): 블록 크기 (기본값은 16)\n",
    "        search_range (int): 탐색 범위 (기본값은 7)\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: 모션 벡터 배열\n",
    "    \"\"\"\n",
    "    height, width = prev_frame.shape[:2]\n",
    "    motion_vectors = np.zeros((height // block_size, width // block_size, 2), dtype=np.int32)\n",
    "\n",
    "    for y in range(0, height, block_size):\n",
    "        for x in range(0, width, block_size):\n",
    "            # 이전 프레임의 블록 추출\n",
    "            prev_block = prev_frame[y:y+block_size, x:x+block_size]\n",
    "\n",
    "            # 현재 프레임에서의 최적의 블록 위치 찾기\n",
    "            best_match = None\n",
    "            best_sad = float('inf')\n",
    "\n",
    "            # 1단계: 중심에서 ±search_range 범위 내에서 탐색\n",
    "            for dy in range(-search_range, search_range+1, 2*search_range):\n",
    "                for dx in range(-search_range, search_range+1, 2*search_range):\n",
    "                    curr_y, curr_x = y + dy, x + dx\n",
    "                    if 0 <= curr_y < height-block_size and 0 <= curr_x < width-block_size:\n",
    "                        curr_block = curr_frame[curr_y:curr_y+block_size, curr_x:curr_x+block_size]\n",
    "                        sad = np.sum(np.abs(prev_block - curr_block))\n",
    "                        if sad < best_sad:\n",
    "                            best_sad = sad\n",
    "                            best_match = (dy, dx)\n",
    "\n",
    "            if best_match is None:\n",
    "                return None\n",
    "            # 2단계: 최적 위치에서 ±search_range//2 범위 내에서 탐색\n",
    "            for dy in range(best_match[0]-search_range//2, best_match[0]+search_range//2+1, search_range//2):\n",
    "                for dx in range(best_match[1]-search_range//2, best_match[1]+search_range//2+1, search_range//2):\n",
    "                    curr_y, curr_x = y + dy, x + dx\n",
    "                    if 0 <= curr_y < height-block_size and 0 <= curr_x < width-block_size:\n",
    "                        curr_block = curr_frame[curr_y:curr_y+block_size, curr_x:curr_x+block_size]\n",
    "                        sad = np.sum(np.abs(prev_block - curr_block))\n",
    "                        if sad < best_sad:\n",
    "                            best_sad = sad\n",
    "                            best_match = (dy, dx)\n",
    "\n",
    "            # 3단계: 최적 위치에서 ±1 범위 내에서 탐색\n",
    "            for dy in range(best_match[0]-1, best_match[0]+2, 1):\n",
    "                for dx in range(best_match[1]-1, best_match[1]+2, 1):\n",
    "                    curr_y, curr_x = y + dy, x + dx\n",
    "                    if 0 <= curr_y < height-block_size and 0 <= curr_x < width-block_size:\n",
    "                        curr_block = curr_frame[curr_y:curr_y+block_size, curr_x:curr_x+block_size]\n",
    "                        sad = np.sum(np.abs(prev_block - curr_block))\n",
    "                        if sad < best_sad:\n",
    "                            best_sad = sad\n",
    "                            best_match = (dy, dx)\n",
    "\n",
    "            motion_vectors[y//block_size, x//block_size] = best_match\n",
    "\n",
    "    return motion_vectors\n",
    "\n",
    "def calculate_angle(points):\n",
    "    if len(points) < 2:\n",
    "        return None\n",
    "    # Fit a line to the points\n",
    "    [vx, vy, x, y] = cv2.fitLine(np.array(points), cv2.DIST_L2, 0, 0.01, 0.01)\n",
    "    # Calculate the angle with the horizontal axis\n",
    "    angle = np.arctan2(vy[0], vx[0]) * 180 / np.pi\n",
    "    return angle\n",
    "\n",
    "def draw_flow(img, flow, step=16):\n",
    "    h, w = img.shape[:2]\n",
    "    y, x = np.mgrid[step/2:h:step, step/2:w:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "    lines = np.vstack([x, y, x+fx, y+fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "\n",
    "    \n",
    "    # 직선 그리기\n",
    "    cv2.polylines(img, lines, 0, (0, 255, 255), lineType=cv2.LINE_AA)\n",
    "    \n",
    "    for (x1, y1), (_x2, _y2) in lines:\n",
    "        cv2.circle(img, (x1, y1), 1, (0, 128, 255), -1, lineType=cv2.LINE_AA)\n",
    "        \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2e95fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, prev_frame = cap.read()\n",
    "    head_positions = []\n",
    "    frames = []\n",
    "\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Set minimum and maximum ellipse size\n",
    "    min_major_axis = 10  # 주축의 최소 길이\n",
    "    min_minor_axis = 10  # 부축의 최소 길이\n",
    "    max_major_axis = 40  # 주축의 최대 길이\n",
    "    max_minor_axis = 40   # 부축의 최대 길이\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        cur_frame = preprocess_frame(frame)\n",
    "        # 결과 이미지 출력\n",
    "        cv2.imshow('Original+high boosted', cur_frame)\n",
    "\n",
    "        # 피부색 검출\n",
    "        skin_mask = detect_skin(cur_frame)\n",
    "        cur_frame_hsv = cv2.cvtColor(cur_frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        masked_v = cv2.bitwise_and(cur_frame_hsv[:, :, 2], cur_frame_hsv[:, :, 2], mask=skin_mask)\n",
    "        cur_frame_hsv[:, :, 2] = masked_v\n",
    "        cur_frame = cv2.cvtColor(cur_frame_hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "        # 바닥 검출\n",
    "        y_position = get_ground(skin_mask)\n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))\n",
    "        cur_frame = cv2.morphologyEx(cur_frame, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        cv2.line(cur_frame, (0, y_position), (cur_frame.shape[1], y_position), (0, 0, 255), thickness=5)\n",
    "        cv2.imshow('skin detection', cur_frame)\n",
    "\n",
    "        gray = cv2.cvtColor(cur_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate optical flow\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "        # Display the result\n",
    "        cv2.imshow('Result', draw_flow(frame, flow))\n",
    "\n",
    "        # 이전 프레임 업데이트\n",
    "        prev_gray = gray.copy()\n",
    "\n",
    "        # frames.append(cur_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    pushup_count = count_pushups(head_positions)\n",
    "    print(f\"Total push-ups: {pushup_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e1dbd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total push-ups: 0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    video_path = \"pushup_sample.mp4\"\n",
    "    main(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6891de96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
